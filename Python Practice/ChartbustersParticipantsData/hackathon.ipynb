{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ChartbustersParticipantsData\\Data_Train.csv\",infer_datetime_format=True,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"ChartbustersParticipantsData\\Data_Test.csv\",infer_datetime_format=True,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Views']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Name = df.Name.str.extract('([0-9a-zA-Z ]*)')\n",
    "df_test.Name = df_test.Name.str.extract('([0-9a-zA-Z ]*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([df,df_test],axis=0,sort=False,ignore_index=True)\n",
    "data.index = data.Unique_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Unique_ID'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Name = data.Name.str.extract('([0-9a-zA-Z ]*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name           1172\n",
       "Genre            21\n",
       "Country           1\n",
       "Song_Name     98072\n",
       "Timestamp     84593\n",
       "Views         53964\n",
       "Comments       2379\n",
       "Likes          9758\n",
       "Popularity     6259\n",
       "Followers      1161\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['Country','Song_Name'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Views = pd.to_numeric(data.Views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in ['Likes','Popularity']:\n",
    "    data[cols] = data[cols].apply(lambda x: x.replace(\",\",''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Likes']=np.where(data['Likes'].str.isnumeric()==False,pd.to_numeric(data['Likes'].apply(lambda x: x[0:-1]))*1000,data['Likes']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Popularity']=np.where(data['Popularity'].str.isnumeric()==False,pd.to_numeric(data['Popularity'].apply(lambda x: x[0:-1]))*1000,data['Popularity']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Timestamp']= pd.to_datetime(data['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest = data['Timestamp'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Timestamp'] = (latest - data['Timestamp'] ).astype('timedelta64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = pd.get_dummies(data.select_dtypes(exclude=np.number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique_ID\n",
       "413890      331\n",
       "249453      980\n",
       "681116     1388\n",
       "387253      626\n",
       "1428029     890\n",
       "           ... \n",
       "183403      544\n",
       "1272578    1129\n",
       "539454      486\n",
       "1543013     543\n",
       "415046     1305\n",
       "Name: Timestamp, Length: 98073, dtype: int32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Timestamp.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Likes_Per_Followers'] = np.where(data.Followers>0,data.Likes/data.Followers,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Comments_Per_Followers'] = np.where(data.Followers>0,data.Comments/data.Followers,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Comments_Per_Likes'] = np.where(data.Likes>0,data.Comments/data.Likes,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Songs_Cnt'] = data[\"Name\"].map(data[\"Name\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Total_Likes'] = data['Name'].map(data.groupby('Name').Likes.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Zero_Likes'] = np.where(data.Likes==0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Zero_Comments'] = np.where(data.Comments==0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Zero_Popularity'] = np.where(data.Popularity==0,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Likes_Per_Timestamp'] = np.where(data.Timestamp>0,data.Likes/data.Timestamp,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['LikesnPopularity'] = data['Likes'] * data['Popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Likes_Per_Popularity'] =  np.where(data.Popularity>0,data.Likes/data.Popularity,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Avg_Likes'] = data['Name'].map(data.groupby('Name').Likes.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98073, 1193)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"Name_\"+ name for name in df.Name.unique().tolist() if name not in df_test.Name.unique().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols.drop(columns = drop_cols,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([cat_cols,data.select_dtypes(include=np.number)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = X[X['Views'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = X[X['Views'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY = trainX.pop('Views').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique_ID\n",
       "562546    NaN\n",
       "907584    NaN\n",
       "213013    NaN\n",
       "340312    NaN\n",
       "41854     NaN\n",
       "           ..\n",
       "183403    NaN\n",
       "1272578   NaN\n",
       "539454    NaN\n",
       "1543013   NaN\n",
       "415046    NaN\n",
       "Name: Views, Length: 19615, dtype: float64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.pop('Views')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso,LassoCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y,test_y = train_test_split(trainX,trainY,test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62766, 1210) (62766,) (15692, 1210) (15692,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape,train_y.shape,test_x.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = LassoCV(n_alphas=['0.1','1','10','0.01'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.4344192107609944e+16, tolerance: 90868133607135.53\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin = Lasso(alpha=0.1)\n",
    "lin.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 1583315.3941994915\n"
     ]
    }
   ],
   "source": [
    "print(\"Train RMSE:\",np.sqrt(mean_squared_error(train_y,lin.predict(train_x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 2063732.3987288144\n"
     ]
    }
   ],
   "source": [
    "print(\"Test RMSE:\",np.sqrt(mean_squared_error(test_y,lin.predict(test_x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unique_ID\n",
       "212750     1299\n",
       "574389      501\n",
       "662009      999\n",
       "962549        1\n",
       "530696      489\n",
       "           ... \n",
       "220974      676\n",
       "1321506     216\n",
       "448409     1877\n",
       "212546      717\n",
       "972679       19\n",
       "Name: Timestamp, Length: 62766, dtype: int32"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.Timestamp.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit(model,trainx,trainy,testx,testy):\n",
    "    model.fit(trainx,trainy)\n",
    "    trainypred = model.predict(trainx)\n",
    "    print(\"Train RMSE:\",np.sqrt(mean_squared_error(trainy,trainypred)))\n",
    "    testypred = model.predict(testx)\n",
    "    print(\"Test RMSE:\",np.sqrt(mean_squared_error(testy,testypred)))\n",
    "    #return testypred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(model,trainx,trainy,testx):\n",
    "    model.fit(trainx,trainy)\n",
    "    trainypred = model.predict(trainx)\n",
    "    print(\"Train RMSE:\",np.sqrt(mean_squared_error(trainy,trainypred)))\n",
    "    testypred = model.predict(testx)\n",
    "    return testypred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(ytest,file):\n",
    "    result_df= pd.DataFrame([ytest]).T\n",
    "    result_df.columns=['Views']\n",
    "    result_df.index = testX.index\n",
    "    writer = ExcelWriter(file+'.xlsx')\n",
    "    result_df.to_excel(writer,index=True)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 2\n",
      "Train RMSE: 450489.63902796403\n",
      "Test RMSE: 862888.77835751\n",
      "i= 3\n",
      "Train RMSE: 447853.0216863948\n",
      "Test RMSE: 717556.9304413007\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,4):\n",
    "    rfr = RandomForestRegressor(random_state=5,n_estimators=i,max_features=0.6)\n",
    "    print(\"i=\",i)\n",
    "    model_fit(rfr,train_x,train_y,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 361618.0188482583\n",
      "Test RMSE: 755460.8465098124\n"
     ]
    }
   ],
   "source": [
    "model_fit(rfr,train_x,train_y,test_x,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import ExcelWriter\n",
    "ytest = model_predict(rfr,trainX,trainY,testX)\n",
    "write_results(ytest,\"RandomForest3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features=0.6, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=3, n_jobs=None,\n",
       "                      oob_score=False, random_state=5, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp = rfr.feature_importances_\n",
    "feat_df = pd.concat([pd.DataFrame(testX.columns),pd.DataFrame(feat_imp)],axis=1)\n",
    "feat_df.columns=['Column','Importance']\n",
    "feat_df.sort_values(by=['Importance'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cols=feat_df.sort_values(by=['Importance'],ascending=False)['Column'].head(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=9:,Test RMSE:705366.6867239755\n"
     ]
    }
   ],
   "source": [
    "for i in range(9,10):\n",
    "    rfr = RandomForestRegressor(random_state=5,n_estimators=3)\n",
    "    #imp_cols=feat_df.sort_values(by=['Importance'],ascending=False)['Column'].head(i)\n",
    "    rfr.fit(train_x[imp_cols],train_y)\n",
    "    testypred=rfr.predict(test_x)\n",
    "    print(\"i={}:,Test RMSE:{}\".format(i,np.sqrt(mean_squared_error(test_y,testypred))))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=50:,Test RMSE:842367.0451245424\n",
      "i=51:,Test RMSE:801593.1010017269\n",
      "i=52:,Test RMSE:801324.5671863026\n",
      "i=53:,Test RMSE:786728.3081632694\n",
      "i=54:,Test RMSE:762283.916528692\n",
      "i=55:,Test RMSE:751762.9073132903\n",
      "i=56:,Test RMSE:785896.4882740595\n",
      "i=57:,Test RMSE:800728.7449786953\n",
      "i=58:,Test RMSE:814520.6866553405\n",
      "i=59:,Test RMSE:791229.5361713163\n"
     ]
    }
   ],
   "source": [
    "for i in range(50,60):\n",
    "    dtr = DecisionTreeRegressor(random_state=5)\n",
    "    imp_cols=feat_df.sort_values(by=['Importance'],ascending=False)['Column'].head(i)\n",
    "    dtr.fit(train_x[imp_cols],train_y)\n",
    "    testypred=dtr.predict(test_x[imp_cols])\n",
    "    print(\"i={}:,Test RMSE:{}\".format(i,np.sqrt(mean_squared_error(test_y,testypred))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 380.687606461636\n"
     ]
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor(random_state=5)\n",
    "imp_cols=feat_df.sort_values(by=['Importance'],ascending=False)['Column'].head(55)\n",
    "ytest = model_predict(dtr,trainX[imp_cols],trainY,testX[imp_cols])\n",
    "write_results(ytest,\"DTree55\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=15:,Test RMSE:1136225.8601206902\n",
      "i=20:,Test RMSE:1112716.393456088\n",
      "i=25:,Test RMSE:1111325.1263528233\n",
      "i=30:,Test RMSE:1182778.6420312307\n",
      "i=35:,Test RMSE:1201285.7889943807\n"
     ]
    }
   ],
   "source": [
    "for i in range(15,40,5):\n",
    "    knn = KNeighborsRegressor(n_neighbors=5)\n",
    "    imp_cols=feat_df.sort_values(by=['Importance'],ascending=False)['Column'].head(i)\n",
    "    x_scaled = StandardScaler().fit_transform(X[imp_cols])\n",
    "    train_x,test_x,train_y,test_y = train_test_split(x_scaled[:trainX.shape[0],:],trainY,test_size=0.2,random_state=5)\n",
    "    knn.fit(train_x,train_y)\n",
    "    testypred=knn.predict(test_x)\n",
    "    print(\"i={}:,Test RMSE:{}\".format(i,np.sqrt(mean_squared_error(test_y,testypred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 773719.4039845001\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "imp_cols=feat_df.sort_values(by=['Importance'],ascending=False)['Column'].head(12)\n",
    "x_scaled = MinMaxScaler().fit_transform(X[imp_cols])\n",
    "xtrain = x_scaled[:trainX.shape[0],:]\n",
    "xtest = x_scaled[trainX.shape[0]:,:]\n",
    "ytestpred =  model_predict(knn,xtrain,trainY,xtest)\n",
    "predictions = [round(value) for value in ytestpred ]\n",
    "write_results(predictions,\"KNNMinMax12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:06:39] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Train RMSE: 328611.71695205546\n"
     ]
    }
   ],
   "source": [
    "\n",
    "xgb = XGBRegressor(random_state=5,n_estimators=200)\n",
    "ytest = model_predict(xgb,trainX[imp_cols],trainY,testX[imp_cols])\n",
    "write_results(ytest,\"XGBoost3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:28:05] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "i=4:,Test RMSE:681832.7582993128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:29:38] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "i=5:,Test RMSE:648465.7880878866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:31:26] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "i=6:,Test RMSE:640780.9182854426\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,7):\n",
    "    xgb = XGBRegressor(random_state=5,n_estimators=500,max_depth=i)\n",
    "    xgb.fit(train_x[imp_cols],train_y)\n",
    "    testypred=xgb.predict(test_x[imp_cols])\n",
    "    print(\"i={}:,Test RMSE:{}\".format(i,np.sqrt(mean_squared_error(test_y,testypred))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1195</td>\n",
       "      <td>Likes</td>\n",
       "      <td>0.316472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1196</td>\n",
       "      <td>Popularity</td>\n",
       "      <td>0.238975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1199</td>\n",
       "      <td>Comments_Per_Likes</td>\n",
       "      <td>0.226605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1194</td>\n",
       "      <td>Comments</td>\n",
       "      <td>0.147453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1207</td>\n",
       "      <td>LikesnPopularity</td>\n",
       "      <td>0.033857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1208</td>\n",
       "      <td>Likes_Per_Popularity</td>\n",
       "      <td>0.021280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1206</td>\n",
       "      <td>Likes_Per_Timestamp</td>\n",
       "      <td>0.002577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1202</td>\n",
       "      <td>Total_Likes</td>\n",
       "      <td>0.002008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1198</td>\n",
       "      <td>Likes_Per_Followers</td>\n",
       "      <td>0.001972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1193</td>\n",
       "      <td>Timestamp</td>\n",
       "      <td>0.001778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1201</td>\n",
       "      <td>Songs_Cnt</td>\n",
       "      <td>0.001455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>Name_BTS</td>\n",
       "      <td>0.000754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1209</td>\n",
       "      <td>Avg_Likes</td>\n",
       "      <td>0.000751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1197</td>\n",
       "      <td>Followers</td>\n",
       "      <td>0.000629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>Comments_Per_Followers</td>\n",
       "      <td>0.000628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1172</td>\n",
       "      <td>Genre_all-music</td>\n",
       "      <td>0.000579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>Name_ILLENIUM</td>\n",
       "      <td>0.000215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>602</td>\n",
       "      <td>Name_Mahritsza</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>Name_Rich The Kid</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1182</td>\n",
       "      <td>Genre_electronic</td>\n",
       "      <td>0.000151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>Name_Adham Seliman</td>\n",
       "      <td>0.000134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>Name_Martin Garrix</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>814</td>\n",
       "      <td>Name_SFiremusic</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Name_</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465</td>\n",
       "      <td>Name_Juice WRLD</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1186</td>\n",
       "      <td>Genre_latin</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>Name_LuisPerez13</td>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1175</td>\n",
       "      <td>Genre_classical</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1191</td>\n",
       "      <td>Genre_rock</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>627</td>\n",
       "      <td>Name_Metro Boomin</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>Name_David Guetta</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>491</td>\n",
       "      <td>Name_Kanye West</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1079</td>\n",
       "      <td>Name_djchorlo</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1177</td>\n",
       "      <td>Genre_danceedm</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>263</td>\n",
       "      <td>Name_Dj Carnage</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>493</td>\n",
       "      <td>Name_Kasbo</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>531</td>\n",
       "      <td>Name_LINKIN</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1189</td>\n",
       "      <td>Genre_rbsoul</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>Name_Future</td>\n",
       "      <td>0.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>Name_Billie Eilish</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>683</td>\n",
       "      <td>Name_NightCore</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1188</td>\n",
       "      <td>Genre_pop</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>528</td>\n",
       "      <td>Name_LIL UZI VERT</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>521</td>\n",
       "      <td>Name_L2Share</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Name_A BOOGIE WIT DA HOODIE</td>\n",
       "      <td>0.000016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>767</td>\n",
       "      <td>Name_R3HAB</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1113</td>\n",
       "      <td>Name_k</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>Name_Dj IsI</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>958</td>\n",
       "      <td>Name_Trippie Redd</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>603</td>\n",
       "      <td>Name_Major Lazer</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>519</td>\n",
       "      <td>Name_Kygo</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1097</td>\n",
       "      <td>Name_galaxy music</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>507</td>\n",
       "      <td>Name_Kodak Black</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949</td>\n",
       "      <td>Name_Travis Scott</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>Name_BachataRomantic</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1038</td>\n",
       "      <td>Name_YoungBoy Never Broke Again</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>Name_DjRene Reyes</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>626</td>\n",
       "      <td>Name_Metanoia Music</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>743</td>\n",
       "      <td>Name_PnB Rock</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>291</td>\n",
       "      <td>Name_EDM</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Column  Importance\n",
       "1195                            Likes    0.316472\n",
       "1196                       Popularity    0.238975\n",
       "1199               Comments_Per_Likes    0.226605\n",
       "1194                         Comments    0.147453\n",
       "1207                 LikesnPopularity    0.033857\n",
       "1208             Likes_Per_Popularity    0.021280\n",
       "1206              Likes_Per_Timestamp    0.002577\n",
       "1202                      Total_Likes    0.002008\n",
       "1198              Likes_Per_Followers    0.001972\n",
       "1193                        Timestamp    0.001778\n",
       "1201                        Songs_Cnt    0.001455\n",
       "84                           Name_BTS    0.000754\n",
       "1209                        Avg_Likes    0.000751\n",
       "1197                        Followers    0.000629\n",
       "1200           Comments_Per_Followers    0.000628\n",
       "1172                  Genre_all-music    0.000579\n",
       "416                     Name_ILLENIUM    0.000215\n",
       "602                    Name_Mahritsza    0.000180\n",
       "790                 Name_Rich The Kid    0.000170\n",
       "1182                 Genre_electronic    0.000151\n",
       "33                 Name_Adham Seliman    0.000134\n",
       "610                Name_Martin Garrix    0.000131\n",
       "814                   Name_SFiremusic    0.000114\n",
       "0                               Name_    0.000096\n",
       "465                   Name_Juice WRLD    0.000062\n",
       "1186                      Genre_latin    0.000049\n",
       "575                  Name_LuisPerez13    0.000046\n",
       "1175                  Genre_classical    0.000045\n",
       "1191                       Genre_rock    0.000042\n",
       "627                 Name_Metro Boomin    0.000042\n",
       "236                 Name_David Guetta    0.000037\n",
       "491                   Name_Kanye West    0.000033\n",
       "1079                    Name_djchorlo    0.000032\n",
       "1177                   Genre_danceedm    0.000030\n",
       "263                   Name_Dj Carnage    0.000030\n",
       "493                        Name_Kasbo    0.000025\n",
       "531                       Name_LINKIN    0.000025\n",
       "1189                     Genre_rbsoul    0.000023\n",
       "348                       Name_Future    0.000023\n",
       "105                Name_Billie Eilish    0.000022\n",
       "683                    Name_NightCore    0.000018\n",
       "1188                        Genre_pop    0.000017\n",
       "528                 Name_LIL UZI VERT    0.000017\n",
       "521                      Name_L2Share    0.000016\n",
       "15        Name_A BOOGIE WIT DA HOODIE    0.000016\n",
       "767                        Name_R3HAB    0.000015\n",
       "1113                           Name_k    0.000015\n",
       "264                       Name_Dj IsI    0.000014\n",
       "958                 Name_Trippie Redd    0.000013\n",
       "603                 Name_Major Lazer     0.000012\n",
       "519                         Name_Kygo    0.000012\n",
       "1097               Name_galaxy music     0.000011\n",
       "507                  Name_Kodak Black    0.000011\n",
       "949                 Name_Travis Scott    0.000010\n",
       "87               Name_BachataRomantic    0.000010\n",
       "1038  Name_YoungBoy Never Broke Again    0.000010\n",
       "273                 Name_DjRene Reyes    0.000009\n",
       "626               Name_Metanoia Music    0.000009\n",
       "743                     Name_PnB Rock    0.000008\n",
       "291                          Name_EDM    0.000008"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_df[feat_df.Importance>0].sort_values(by=['Importance'],ascending=False).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cols=feat_df.sort_values(by=['Importance'],ascending=False)['Column'].head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeRegressor(random_state=5,max_features=12)\n",
    "rfr = RandomForestRegressor(random_state=5,n_estimators=3,max_features=41)\n",
    "voting = VotingRegressor(estimators=[\n",
    "('DTree',dtree),('RanFor',rfr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 259290.8072595667\n"
     ]
    }
   ],
   "source": [
    "ytest = model_predict(voting,trainX[imp_cols],trainY,testX[imp_cols])\n",
    "write_results(ytest,\"Voting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostRegressor(random_state=5,n_estimators=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 985410.9594317797\n"
     ]
    }
   ],
   "source": [
    "imp_cols=feat_df.sort_values(by=['Importance'],ascending=False)['Column'].head(12)\n",
    "ytest = model_predict(ada,trainX[imp_cols],trainY,testX[imp_cols])\n",
    "write_results(ytest,\"AdaBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(random_state=5,max_features=0.1,n_estimators=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 582768.1920734084\n"
     ]
    }
   ],
   "source": [
    "ytest = model_predict(gbr,trainX[imp_cols],trainY,testX[imp_cols])\n",
    "write_results(ytest,\"GradientBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0.1:,Test RMSE:1016176.5525098592\n",
      "i=0.2:,Test RMSE:877884.5501042964\n",
      "i=0.3:,Test RMSE:863464.6801454258\n",
      "i=0.4:,Test RMSE:732602.348306347\n",
      "i=0.5:,Test RMSE:682597.5831010077\n",
      "i=0.6:,Test RMSE:729052.2634500534\n",
      "i=0.7:,Test RMSE:701561.3541226087\n",
      "i=0.8:,Test RMSE:681433.0326316672\n",
      "i=0.9:,Test RMSE:706113.5087218691\n",
      "i=1:,Test RMSE:3392530.1894489764\n"
     ]
    }
   ],
   "source": [
    "for i in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]:\n",
    "    dtr = GradientBoostingRegressor(random_state=5,max_features=i,n_estimators=150)\n",
    "    #imp_cols=feat_df.sort_values(by=['Importance'],ascending=False)['Column'].head(i)\n",
    "    dtr.fit(train_x,train_y)\n",
    "    testypred=dtr.predict(test_x)\n",
    "    print(\"i={}:,Test RMSE:{}\".format(i,np.sqrt(mean_squared_error(test_y,testypred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 443449.1836877321\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(random_state=5,max_features=0.8, n_estimators=75)\n",
    "ytest = model_predict(gbr,trainX,trainY,testX)\n",
    "write_results(ytest,\"GBR1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cols=feat_df.sort_values(by=['Importance'],ascending=False)['Column'].head(20)\n",
    "trainXpoly = poly.fit_transform(trainX[imp_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "testXpoly = poly.transform(testX[imp_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 289047.50823923585\n"
     ]
    }
   ],
   "source": [
    "ytest = model_predict(rfr,trainXpoly,trainY,testXpoly)\n",
    "write_results(ytest,\"Polynomial_RFR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=20,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=5, splitter='best')"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp_cols=feat_df.sort_values(by=['Importance'],ascending=False)['Column'].head(20)\n",
    "DT = DecisionTreeRegressor(random_state=5, max_features=20)\n",
    "DT.fit(trainX[imp_cols],trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy_DT = DT.predict(testX[imp_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(random_state=5,n_estimators=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cols=feat_df.sort_values(by=['Importance'],ascending=False)['Column'].head(60)\n",
    "rfr.fit(trainX[imp_cols],trainY)\n",
    "testy_RF = rfr.predict(testX[imp_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 60 and input n_features is 231 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-248-58d4ffae630c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgbr\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgbr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainXpoly\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtesty_GBR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestXpoly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    357\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    400\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                              % (self.n_features_, n_features))\n\u001b[0m\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 60 and input n_features is 231 "
     ]
    }
   ],
   "source": [
    "gbr= GradientBoostingRegressor(random_state=5)\n",
    "gbr.fit(trainXpoly,trainY)\n",
    "testy_GBR = rfr.predict(testXpoly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = np.mean([testy_DT\n",
    "                              ,testy_RF\n",
    "                             ], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([214042.9875,  30803.2875,  15332.225 , ...,   4142.    ,\n",
       "       101363.35  ,  21217.4875])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.columns=['Views']\n",
    "result_df.index = testX.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = ExcelWriter('MeanTree.xlsx')\n",
    "result_df.to_excel(writer,index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique_ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>562546</td>\n",
       "      <td>214042.9875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>907584</td>\n",
       "      <td>30803.2875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213013</td>\n",
       "      <td>15332.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340312</td>\n",
       "      <td>32708.9875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41854</td>\n",
       "      <td>8542.1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183403</td>\n",
       "      <td>65378.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1272578</td>\n",
       "      <td>99054.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>539454</td>\n",
       "      <td>4142.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1543013</td>\n",
       "      <td>101363.3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415046</td>\n",
       "      <td>21217.4875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19615 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Views\n",
       "Unique_ID             \n",
       "562546     214042.9875\n",
       "907584      30803.2875\n",
       "213013      15332.2250\n",
       "340312      32708.9875\n",
       "41854        8542.1875\n",
       "...                ...\n",
       "183403      65378.4500\n",
       "1272578     99054.7500\n",
       "539454       4142.0000\n",
       "1543013    101363.3500\n",
       "415046      21217.4875\n",
       "\n",
       "[19615 rows x 1 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-3562abcf1323>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrfr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mytest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mwrite_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mytest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"RFR\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-d46d39732e93>\u001b[0m in \u001b[0;36mmodel_predict\u001b[1;34m(model, trainx, trainy, testx)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmodel_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtrainypred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train RMSE:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainypred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtestypred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 330\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1155\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1158\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor(random_state=5,n_estimators=1000,max_features=0.1)\n",
    "ytest = model_predict(rfr,trainX,trainY,testX)\n",
    "write_results(ytest,\"RFR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed: 16.4min\n",
      "[Parallel(n_jobs=2)]: Done 135 out of 135 | elapsed: 46.3min finished\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9692657134175081\n",
      "{'colsample_bytree': 0.7, 'learning_rate': 0.07, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 500, 'nthread': 2, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBRegressor()\n",
    "parameters = {'nthread':[2], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [100,200,500],\n",
    "              'max'}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 5,\n",
    "                        n_jobs = 2,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(trainX[imp_cols],\n",
    "         trainY)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "xgb1 = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = XGBRegressor(colsample_bytree= 0.7, learning_rate= 0.07, max_depth=5, min_child_weight= 4, n_estimators= 500, nthread= 2, objective= 'reg:linear', silent= 1, subsample= 0.7, max_features=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:3.99289e+06\n",
      "Will train until validation_0-rmse hasn't improved in 5 rounds.\n",
      "[25]\tvalidation_0-rmse:1.13001e+06\n",
      "[50]\tvalidation_0-rmse:733185\n",
      "[75]\tvalidation_0-rmse:687753\n",
      "Stopping. Best iteration:\n",
      "[74]\tvalidation_0-rmse:687368\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.7, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.07, max_delta_step=0,\n",
       "             max_depth=5, max_features=0.8, min_child_weight=4, missing=None,\n",
       "             n_estimators=500, n_jobs=1, nthread=2, objective='reg:linear',\n",
       "             random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "             seed=None, silent=1, subsample=0.7, verbosity=1)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbr.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=5, eval_metric=\"rmse\",verbose=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY=xgbr.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 382029.08042337326\n"
     ]
    }
   ],
   "source": [
    "xgbr = XGBRegressor(n_estimators=74, max_features=0.8, colsample_bytree= 0.7, learning_rate= 0.07, max_depth=5, min_child_weight= 4, nthread= 2, objective= 'reg:linear', silent= 1, subsample= 0.7)\n",
    "testy = model_predict(xgbr,trainX,trainY,testX)\n",
    "# make predictions for test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(value) if value>0 else 0 for value in testy ]\n",
    "write_results(predictions,\"XGBRGridCV2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\lightgbm\\callback.py:188: UserWarning: Early stopping is not available in dart mode\n",
      "  warnings.warn('Early stopping is not available in dart mode')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid's rmse: 919277\n",
      "[200]\tvalid's rmse: 859791\n",
      "[300]\tvalid's rmse: 788422\n",
      "[400]\tvalid's rmse: 759870\n",
      "[500]\tvalid's rmse: 754670\n",
      "[600]\tvalid's rmse: 756325\n",
      "[700]\tvalid's rmse: 743843\n",
      "[800]\tvalid's rmse: 742173\n",
      "[900]\tvalid's rmse: 742669\n",
      "[1000]\tvalid's rmse: 725650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_fit_params={\"early_stopping_rounds\":50, \n",
    "            \"eval_metric\" : 'rmse', \n",
    "            \"eval_set\" : [(test_x,test_y)],\n",
    "            'eval_names': ['valid'],\n",
    "            'verbose':100\n",
    "           }\n",
    "\n",
    "lgb_params = {'boosting_type': 'gbdt',\n",
    " 'metric': 'rmse',\n",
    " 'verbose': 0,\n",
    " 'bagging_fraction': 0.8,\n",
    " 'bagging_freq': 1,\n",
    " 'feature_fraction': 0.8,\n",
    " 'lambda_l1': 0.01,\n",
    " 'lambda_l2': 0.01,\n",
    " 'learning_rate': 0.1,\n",
    " 'max_bin': 255,\n",
    " 'max_depth': -1,\n",
    " 'min_data_in_bin': 1,\n",
    " 'min_data_in_leaf': 1,\n",
    " 'num_leaves': 31}\n",
    "lgb_params\n",
    "\n",
    "clf_lgb = lgb.LGBMRegressor(n_estimators=1000, **lgb_params, random_state=5, n_jobs=2)\n",
    "clf_lgb.fit(train_x, train_y, **lgb_fit_params)\n",
    "clf_lgb.best_iteration_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.8, bagging_freq=1, boosting_type='gbdt',\n",
       "              class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,\n",
       "              importance_type='split', lambda_l1=0.01, lambda_l2=0.01,\n",
       "              learning_rate=0.1, max_bin=255, max_depth=-1, metric='rmse',\n",
       "              min_child_samples=20, min_child_weight=0.001, min_data_in_bin=1,\n",
       "              min_data_in_leaf=1, min_split_gain=0.0, n_estimators=508,\n",
       "              n_jobs=2, num_leaves=31, objective=None, random_state=5,\n",
       "              reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "              subsample_for_bin=200000, subsample_freq=0, verbose=0)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lgb_full = lgb.LGBMRegressor(n_estimators=int(clf_lgb.best_iteration_*1.2), **lgb_params, random_state=5, n_jobs=2)\n",
    "clf_lgb_full.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 72964.70008252536\n"
     ]
    }
   ],
   "source": [
    "ytest = model_predict(clf_lgb_full,trainX[imp_cols],trainY,testX[imp_cols])\n",
    "write_results(ytest,\"LightGBMR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                            Queen\n",
       "Genre                            rock\n",
       "Timestamp                        4140\n",
       "Views                             NaN\n",
       "Comments                            0\n",
       "Likes                               3\n",
       "Popularity                          0\n",
       "Followers                       70299\n",
       "Followers_Per_Likes             23433\n",
       "Followers_Per_Comments              0\n",
       "Likes_Per_Comments                  0\n",
       "Songs_Cnt                         689\n",
       "Zero_Likes                          0\n",
       "Zero_Comments                       1\n",
       "Zero_Popularity                     1\n",
       "Likes_Per_Timestamp       0.000724638\n",
       "LikesnPopularity                    0\n",
       "Likes_Per_Popularity                0\n",
       "Mean_Popularity               1.51234\n",
       "Avg_Likes                     230.435\n",
       "Name: 1120309, dtype: object"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[1120309]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Views</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Followers_Per_Likes</th>\n",
       "      <th>Followers_Per_Comments</th>\n",
       "      <th>Likes_Per_Comments</th>\n",
       "      <th>Songs_Cnt</th>\n",
       "      <th>Zero_Likes</th>\n",
       "      <th>Zero_Comments</th>\n",
       "      <th>Zero_Popularity</th>\n",
       "      <th>Likes_Per_Timestamp</th>\n",
       "      <th>LikesnPopularity</th>\n",
       "      <th>Likes_Per_Popularity</th>\n",
       "      <th>Mean_Popularity</th>\n",
       "      <th>Avg_Likes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1120183</td>\n",
       "      <td>Queen</td>\n",
       "      <td>rock</td>\n",
       "      <td>2977.0</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>70299</td>\n",
       "      <td>8787.375000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.512337</td>\n",
       "      <td>230.435414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120262</td>\n",
       "      <td>Queen</td>\n",
       "      <td>rock</td>\n",
       "      <td>2977.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>70299</td>\n",
       "      <td>23433.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.512337</td>\n",
       "      <td>230.435414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120467</td>\n",
       "      <td>Queen</td>\n",
       "      <td>rock</td>\n",
       "      <td>10282.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70299</td>\n",
       "      <td>70299.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.512337</td>\n",
       "      <td>230.435414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120113</td>\n",
       "      <td>Queen</td>\n",
       "      <td>rock</td>\n",
       "      <td>2977.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>70299</td>\n",
       "      <td>6390.818182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.512337</td>\n",
       "      <td>230.435414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1119950</td>\n",
       "      <td>Queen</td>\n",
       "      <td>rock</td>\n",
       "      <td>1516.0</td>\n",
       "      <td>5023.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>70299</td>\n",
       "      <td>7029.900000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>20</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.512337</td>\n",
       "      <td>230.435414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1119916</td>\n",
       "      <td>Queen</td>\n",
       "      <td>rock</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>13</td>\n",
       "      <td>70299</td>\n",
       "      <td>275.682353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.976744</td>\n",
       "      <td>3315</td>\n",
       "      <td>19.615385</td>\n",
       "      <td>1.512337</td>\n",
       "      <td>230.435414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1119931</td>\n",
       "      <td>Queen</td>\n",
       "      <td>rock</td>\n",
       "      <td>857.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>70299</td>\n",
       "      <td>3056.478261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026838</td>\n",
       "      <td>115</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>1.512337</td>\n",
       "      <td>230.435414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120618</td>\n",
       "      <td>Queen</td>\n",
       "      <td>rock</td>\n",
       "      <td>10282.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>70299</td>\n",
       "      <td>10042.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.512337</td>\n",
       "      <td>230.435414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120638</td>\n",
       "      <td>Queen</td>\n",
       "      <td>rock</td>\n",
       "      <td>10282.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>70299</td>\n",
       "      <td>4686.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.512337</td>\n",
       "      <td>230.435414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120485</td>\n",
       "      <td>Queen</td>\n",
       "      <td>rock</td>\n",
       "      <td>10282.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>70299</td>\n",
       "      <td>35149.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.512337</td>\n",
       "      <td>230.435414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows  20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name Genre  Timestamp   Views  Comments  Likes  Popularity  \\\n",
       "Unique_ID                                                                \n",
       "1120183    Queen  rock     2977.0  2701.0         0      8           0   \n",
       "1120262    Queen  rock     2977.0   720.0         0      3           0   \n",
       "1120467    Queen  rock    10282.0    63.0         0      1           0   \n",
       "1120113    Queen  rock     2977.0  1053.0         0     11           0   \n",
       "1119950    Queen  rock     1516.0  5023.0         0     10           2   \n",
       "...          ...   ...        ...     ...       ...    ...         ...   \n",
       "1119916    Queen  rock      129.0     NaN         0    255          13   \n",
       "1119931    Queen  rock      857.0     NaN         0     23           5   \n",
       "1120618    Queen  rock    10282.0     NaN         0      7           0   \n",
       "1120638    Queen  rock    10282.0     NaN         0     15           0   \n",
       "1120485    Queen  rock    10282.0     NaN         0      2           0   \n",
       "\n",
       "           Followers  Followers_Per_Likes  Followers_Per_Comments  \\\n",
       "Unique_ID                                                           \n",
       "1120183        70299          8787.375000                     0.0   \n",
       "1120262        70299         23433.000000                     0.0   \n",
       "1120467        70299         70299.000000                     0.0   \n",
       "1120113        70299          6390.818182                     0.0   \n",
       "1119950        70299          7029.900000                     0.0   \n",
       "...              ...                  ...                     ...   \n",
       "1119916        70299           275.682353                     0.0   \n",
       "1119931        70299          3056.478261                     0.0   \n",
       "1120618        70299         10042.714286                     0.0   \n",
       "1120638        70299          4686.600000                     0.0   \n",
       "1120485        70299         35149.500000                     0.0   \n",
       "\n",
       "           Likes_Per_Comments  Songs_Cnt  Zero_Likes  Zero_Comments  \\\n",
       "Unique_ID                                                             \n",
       "1120183                   0.0        689           0              1   \n",
       "1120262                   0.0        689           0              1   \n",
       "1120467                   0.0        689           0              1   \n",
       "1120113                   0.0        689           0              1   \n",
       "1119950                   0.0        689           0              1   \n",
       "...                       ...        ...         ...            ...   \n",
       "1119916                   0.0        689           0              1   \n",
       "1119931                   0.0        689           0              1   \n",
       "1120618                   0.0        689           0              1   \n",
       "1120638                   0.0        689           0              1   \n",
       "1120485                   0.0        689           0              1   \n",
       "\n",
       "           Zero_Popularity  Likes_Per_Timestamp  LikesnPopularity  \\\n",
       "Unique_ID                                                           \n",
       "1120183                  1             0.002687                 0   \n",
       "1120262                  1             0.001008                 0   \n",
       "1120467                  1             0.000097                 0   \n",
       "1120113                  1             0.003695                 0   \n",
       "1119950                  0             0.006596                20   \n",
       "...                    ...                  ...               ...   \n",
       "1119916                  0             1.976744              3315   \n",
       "1119931                  0             0.026838               115   \n",
       "1120618                  1             0.000681                 0   \n",
       "1120638                  1             0.001459                 0   \n",
       "1120485                  1             0.000195                 0   \n",
       "\n",
       "           Likes_Per_Popularity  Mean_Popularity   Avg_Likes  \n",
       "Unique_ID                                                     \n",
       "1120183                0.000000         1.512337  230.435414  \n",
       "1120262                0.000000         1.512337  230.435414  \n",
       "1120467                0.000000         1.512337  230.435414  \n",
       "1120113                0.000000         1.512337  230.435414  \n",
       "1119950                5.000000         1.512337  230.435414  \n",
       "...                         ...              ...         ...  \n",
       "1119916               19.615385         1.512337  230.435414  \n",
       "1119931                4.600000         1.512337  230.435414  \n",
       "1120618                0.000000         1.512337  230.435414  \n",
       "1120638                0.000000         1.512337  230.435414  \n",
       "1120485                0.000000         1.512337  230.435414  \n",
       "\n",
       "[689 rows x 20 columns]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data.Name=='Queen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
