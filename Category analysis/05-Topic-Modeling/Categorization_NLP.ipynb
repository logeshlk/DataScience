{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('ModuleReviews.csv', encoding = \"ISO-8859-1\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REVIEW</th>\n",
       "      <th>SENTIMENT</th>\n",
       "      <th>Module</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Update: Now that the tech issues have been add...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Changing my rating since the problems are fixe...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>App worked pretty much as expected. Could have...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Maps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Highly recommend when you travel with Air Cana...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Application Crashes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The app went from very useful to absolutely us...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Application Crashes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825</td>\n",
       "      <td>This app works OK generally but I have been ha...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>My trips page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>826</td>\n",
       "      <td>Whenever I get a notification about a flight f...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Application Crashes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>827</td>\n",
       "      <td>I travel a lot on a number of airlines. Delta ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>My trips page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>828</td>\n",
       "      <td>Had to keep adding my flight info so I could u...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Error Messages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>829</td>\n",
       "      <td>This app loves to fail just as I'm approaching...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>My trips page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                REVIEW SENTIMENT  \\\n",
       "0    Update: Now that the tech issues have been add...  Positive   \n",
       "1    Changing my rating since the problems are fixe...  Positive   \n",
       "2    App worked pretty much as expected. Could have...  Positive   \n",
       "3    Highly recommend when you travel with Air Cana...  Positive   \n",
       "4    The app went from very useful to absolutely us...  Positive   \n",
       "..                                                 ...       ...   \n",
       "825  This app works OK generally but I have been ha...  Negative   \n",
       "826  Whenever I get a notification about a flight f...  Negative   \n",
       "827  I travel a lot on a number of airlines. Delta ...  Positive   \n",
       "828  Had to keep adding my flight info so I could u...  Negative   \n",
       "829  This app loves to fail just as I'm approaching...  Negative   \n",
       "\n",
       "                  Module  \n",
       "0                 Update  \n",
       "1                 Update  \n",
       "2                   Maps  \n",
       "3    Application Crashes  \n",
       "4    Application Crashes  \n",
       "..                   ...  \n",
       "825        My trips page  \n",
       "826  Application Crashes  \n",
       "827        My trips page  \n",
       "828       Error Messages  \n",
       "829        My trips page  \n",
       "\n",
       "[830 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    828\n",
       "True       2\n",
       "Name: Module, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['Module'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Module'] = Data['Module'].fillna(Data['Module'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    830\n",
       "Name: Module, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['Module'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User Experience        314\n",
       "My trips page          110\n",
       "Application Crashes     65\n",
       "Update                  64\n",
       "Flight Status           50\n",
       "Booking Page            49\n",
       "Login Issues            45\n",
       "Check-in                30\n",
       "Boarding                30\n",
       "Baggage page            16\n",
       "Error Messages          14\n",
       "Payment Page            13\n",
       "User Data issue         11\n",
       "Maps                     6\n",
       "Navigation               4\n",
       "Seat selection           4\n",
       "Calender                 2\n",
       "Tracking                 2\n",
       "Search page              1\n",
       "Name: Module, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['Module'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.Module.replace({\"Tracking\":\"Flight Status\", \"Search page\":\"Booking Page\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User Experience        314\n",
       "My trips page          110\n",
       "Application Crashes     65\n",
       "Update                  64\n",
       "Flight Status           52\n",
       "Booking Page            50\n",
       "Login Issues            45\n",
       "Check-in                30\n",
       "Boarding                30\n",
       "Baggage page            16\n",
       "Error Messages          14\n",
       "Payment Page            13\n",
       "User Data issue         11\n",
       "Maps                     6\n",
       "Navigation               4\n",
       "Seat selection           4\n",
       "Calender                 2\n",
       "Name: Module, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['Module'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique values : 17\n",
      "List of Unique values : ['Update' 'Maps' 'Application Crashes' 'Payment Page' 'Flight Status'\n",
      " 'User Experience' 'Booking Page' 'My trips page' 'Boarding' 'Check-in'\n",
      " 'Login Issues' 'User Data issue' 'Baggage page' 'Error Messages'\n",
      " 'Calender' 'Seat selection' 'Navigation ']\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of Unique values :\", Data['Module'].nunique())\n",
    "print (\"List of Unique values :\", Data['Module'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ecc84ab648>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='Module', data=Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = Data['REVIEW'].values\n",
    "Categories = Data['Module'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Wrangling and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import tqdm\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function defined to remove html tags from data\n",
    "\n",
    "def strip_html_tags(text):\n",
    "  soup = BeautifulSoup(text, \"html.parser\")\n",
    "  [s.extract() for s in soup(['iframe', 'script'])]\n",
    "  stripped_text = soup.get_text()\n",
    "  stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
    "  return stripped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function defined to remove unicode data\n",
    "\n",
    "def remove_accented_chars(text):\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case and remove special characters\\whitespaces\n",
    "\n",
    "def pre_process_corpus(docs):\n",
    "  norm_docs = []\n",
    "  for doc in tqdm.tqdm(docs):\n",
    "    doc = strip_html_tags(doc)\n",
    "    doc = doc.translate(doc.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "    doc = doc.lower()\n",
    "    doc = remove_accented_chars(doc)\n",
    "    #doc = contractions.fix(doc)\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z0-9\\s]', '', doc, re.I|re.A)\n",
    "    doc = re.sub(' +', ' ', doc)\n",
    "    doc = doc.strip()  \n",
    "    norm_docs.append(doc)\n",
    "  \n",
    "  return norm_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 830/830 [00:00<00:00, 2582.18it/s]\n"
     ]
    }
   ],
   "source": [
    "norm_reviews = pre_process_corpus(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vecotorizer \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build BOW features on train reviews\n",
    "cv = CountVectorizer(min_df=5, max_df=0.95,stop_words='english', ngram_range=(1,2))\n",
    "cv_features = cv.fit_transform(norm_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<830x862 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 13912 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build TFIDF features on train reviews\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=5, max_df=1.0, ngram_range=(1,2),\n",
    "                     sublinear_tf=True, stop_words='english')\n",
    "tv_features = tv.fit_transform(norm_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA - Latent Drichhlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=10,random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=10, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=40, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.fit(cv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 20 WORDS FOR TOPIC #0\n",
      "['having', 'number', 'delta app', 'crashes', 'work', 'trips', 'fly', 'phone', 'trip', 'just', 'boarding passes', 'use', 'passes', 'time', 'flight', 'boarding pass', 'pass', 'delta', 'boarding', 'app']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #1\n",
      "['time', 'know', 'working', 'great app', 'dont', 'easy', 'updates', 'works', 'delta', 'airline', 'fly', 'needs', 'boarding', 'like', 'flight', 'use', 'just', 'flights', 'great', 'app']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #2\n",
      "['good', 'day', 'flights', 'pass', 'flying', 'log', 'flight', 'easy', 'easy use', 'time', 'booking', 'account', 'password', 'use', 'better', 'works', 'air canada', 'air', 'canada', 'app']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #3\n",
      "['tried', 'does', 'information', 'phone', 'ive', 'number', 'security', 'check', 'times', 'use', 'gate', 'boarding passes', 'just', 'flight', 'passes', 'time', 'boarding pass', 'pass', 'boarding', 'app']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #4\n",
      "['just', 'trips', 'right', 'flight', 'like', 'work', 'fixed', 'need', 'says', 'use', 'seat', 'update', 'trip', 'boarding pass', 'confirmation', 'pass', 'flights', 'boarding', 'number', 'app']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #5\n",
      "['booking', 'code', 'ticket', 'checked', 'used', 'like', 'delta', 'number', 'check', 'way', 'flights', 'doesnt', 'credit card', 'credit', 'website', 'time', 'card', 'info', 'app', 'flight']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #6\n",
      "['boarding', 'worked', 'boarding passes', 'app worked', 'does', 'gate', 'passes', 'notifications', 'updated', 'version', 'pretty', 'need', 'checkin', 'use', 'trip', 'good app', 'info', 'flight', 'good', 'app']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #7\n",
      "['airline', 'altitude', 'status', 'like', 'old', 'new app', 'password', 'friendly', 'user friendly', 'great', 'going', 'really', 'interface', 'information', 'flights', 'best', 'boarding', 'user', 'new', 'app']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #8\n",
      "['error', 'youre', 'useful', 'does', 'look', 'delta', 'just', 'bag', 'seat', 'information', 'doesnt', 'gate', 'airport', 'boarding pass', 'pass', 'time', 'check', 'flight', 'boarding', 'app']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #9\n",
      "['air', 'make', 'time', 'provide', 'allow', 'love', 'pay luggage', 'simple', 'crash', 'great', 'reservation', 'return', 'pay', 'check', 'flights', 'way', 'information', 'app', 'luggage', 'flight']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,topic in enumerate(LDA.components_):\n",
    "    print(f'THE TOP 20 WORDS FOR TOPIC #{index}')\n",
    "    print([cv.get_feature_names()[i] for i in topic.argsort()[-20:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Unique values : ['Update' 'Maps' 'Application Crashes' 'Payment Page' 'Flight Status'\n",
      " 'User Experience' 'Booking Page' 'My trips page' 'Boarding' 'Check-in'\n",
      " 'Login Issues' 'User Data issue' 'Baggage page' 'Error Messages'\n",
      " 'Calender' 'Seat selection' 'Navigation ']\n"
     ]
    }
   ],
   "source": [
    "print (\"List of Unique values :\", Data['Module'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=10, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=40, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.fit(tv_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "862"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 20 WORDS FOR TOPIC #0\n",
      "['app works', 'tried', 'experience', 'times', 'ac', 'just', 'flight', 'better', 'use', 'time', 'boarding pass', 'work', 'boarding', 'works', 'pass', 'airlines', 'delta', 'new', 'log', 'app']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #1\n",
      "['boarding', 'issue', 'reviews', 'dont', 'makes', 'just', 'easy', 'apps', 'checkin', 'functionality', 'needs', 'flights', 'updates', 'like', 'friendly', 'user friendly', 'great app', 'user', 'great', 'app']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #2\n",
      "['using', 'login', 'booked', 'version', 'boarding pass', 'pass', 'account', 'flight', 'boarding', 'reset', 'password', 'flights', 'info', 'time', 'excellent', 'crashes', 'app', 'use', 'easy use', 'easy']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #3\n",
      "['doesnt', 'useless', 'flights', 'confirmation', 'works', 'great', 'open', 'flight', 'information', 'delta', 'working', 'boarding pass', 'just', 'use', 'time', 'pass', 'boarding', 'number', 'having', 'app']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #4\n",
      "['fields', 'fast', 'info', 'love', 'used', 'boarding', 'gate', 'click', 'flight', 'option', 'bad', 'great', 'flights', 'calendar', 'convenient', 'service', 'good airline', 'app', 'airline', 'good']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #5\n",
      "['card', 'time', 'store', 'ticket', 'boarding', 'airline', 'phone', 'code', 'great', 'counter', 'good', 'test', 'notifications', 'thank', 'delta', 'canada', 'air', 'air canada', 'flight', 'app']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #6\n",
      "['updating', 'use', 'smooth', 'pretty', 'passes', 'boarding passes', 'remember', 'updated', 'pretty good', 'wants', 'version', 'info', 'previous', 'add', 'flight', 'reservation', 'need', 'app', 'good app', 'good']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #7\n",
      "['did', 'user', 'useful', 'wonderful', 'wont', 'great', 'update', 'flight information', 'let', 'useful app', 'boarding pass', 'baggage', 'fast', 'pass', 'far', 'information', 'boarding', 'flight', 'works', 'app']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #8\n",
      "['checked', 'says', 'useful', 'version', 'look', 'delta', 'keeps', 'trip', 'ease', 'airport', 'flight', 'gate', 'time', 'need', 'check', 'app', 'pass', 'boarding pass', 'does', 'boarding']\n",
      "\n",
      "\n",
      "THE TOP 20 WORDS FOR TOPIC #9\n",
      "['save boarding', 'boarding', 'track inbound', 'boarding passes', 'return', 'new app', 'crash', 'works', 'save', 'passes', 'new', 'checkin', 'pay', 'great', 'google', 'app', 'google pay', 'love', 'simple', 'best']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,topic in enumerate(LDA.components_):\n",
    "    print(f'THE TOP 20 WORDS FOR TOPIC #{index}')\n",
    "    print([cv.get_feature_names()[i] for i in topic.argsort()[-20:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word 2 Vec in LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import smart_open\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus(object):\n",
    "    \"\"\"An interator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = Data\n",
    "        for line in open(corpus_path):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = norm_reviews\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
